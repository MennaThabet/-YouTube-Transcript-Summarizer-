{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T19:29:54.520638Z","iopub.execute_input":"2026-01-06T19:29:54.520885Z","iopub.status.idle":"2026-01-06T19:29:56.728421Z","shell.execute_reply.started":"2026-01-06T19:29:54.520857Z","shell.execute_reply":"2026-01-06T19:29:56.727518Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"pip install youtube-transcript-api","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T19:31:57.379883Z","iopub.execute_input":"2026-01-06T19:31:57.380153Z","iopub.status.idle":"2026-01-06T19:32:01.790984Z","shell.execute_reply.started":"2026-01-06T19:31:57.380120Z","shell.execute_reply":"2026-01-06T19:32:01.790005Z"}},"outputs":[{"name":"stdout","text":"Collecting youtube-transcript-api\n  Downloading youtube_transcript_api-1.2.3-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api) (0.7.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (2025.11.12)\nDownloading youtube_transcript_api-1.2.3-py3-none-any.whl (485 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.1/485.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: youtube-transcript-api\nSuccessfully installed youtube-transcript-api-1.2.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from urllib.parse import urlparse, parse_qs\nfrom youtube_transcript_api import YouTubeTranscriptApi\n\ndef extract_video_id(url: str) -> str:\n    \"\"\"\n    Extract the YouTube video ID from a URL.\n    Raises ValueError if no 'v' parameter is found.\n    \"\"\"\n    parsed = urlparse(url)\n    qs = parse_qs(parsed.query)\n    video_ids = qs.get('v')\n\n    if not video_ids:\n        raise ValueError(f\"No video id found in URL: {url}\")\n    return video_ids[0]\n\nif __name__ == \"__main__\":\n    url = \"https://www.youtube.com/watch?v=iG9CE55wbtY&list=PL68492A0FC99185C7\"\n\n    video_id = extract_video_id(url)\n\n    api = YouTubeTranscriptApi()\n    fetched = api.fetch(video_id, languages=['en']) # returns a FetchedTranscript\n\n    text = \"\\n\".join(snippet.text for snippet in fetched)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T19:34:28.374624Z","iopub.execute_input":"2026-01-06T19:34:28.375068Z","iopub.status.idle":"2026-01-06T19:34:29.348779Z","shell.execute_reply.started":"2026-01-06T19:34:28.375032Z","shell.execute_reply":"2026-01-06T19:34:29.348033Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def chunk_text(text, max_chars = 3500, chunk_size = 200):\n    \"\"\"\n    Because facebook/bart-large-cnn model is limited to 1024 tokens,\n    we will chunk the text into 200 tokens for each chunk\n    \"\"\"\n    chunks = []\n    start = 0\n    while start < len(text):\n        end = start + max_chars\n        chunk = text[start:end]\n        chunks.append(chunk)\n        if (end >= len(text)):\n            break\n        start = end + 1\n    return chunks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T19:34:46.219589Z","iopub.execute_input":"2026-01-06T19:34:46.220007Z","iopub.status.idle":"2026-01-06T19:34:46.225057Z","shell.execute_reply.started":"2026-01-06T19:34:46.219965Z","shell.execute_reply":"2026-01-06T19:34:46.224147Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Use a pipeline as a high-level helper\nfrom transformers import pipeline\n\npipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T19:34:55.297232Z","iopub.execute_input":"2026-01-06T19:34:55.297949Z","iopub.status.idle":"2026-01-06T19:35:30.529902Z","shell.execute_reply.started":"2026-01-06T19:34:55.297888Z","shell.execute_reply":"2026-01-06T19:35:30.529299Z"}},"outputs":[{"name":"stderr","text":"2026-01-06 19:35:05.543607: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767728105.750957      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767728105.808789      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767728106.313204      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767728106.313237      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767728106.313240      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767728106.313242      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c71ca795761741c1b9c309856dd8fd32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ff728ee2be24ee5bcd552f1509bf0d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c38b998d8c6b489c899486b09c2aa0ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eee944349b048ce8e84cd8024fcaabc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1f116babc804bf8ba66b2e5eceff4ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cb70be0dbfd4be0aa16e79cc1eade0a"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#print(pipe(text, max_length=130, min_length=30, do_sample=True))\nchunks = chunk_text(text)\nsummaries = []\nfor i, chunk in enumerate(chunks):\n    print(f\"Summarizing chunk {i+1} of {len(chunks)}\")\n    summary = pipe(chunk, max_length=130, min_length=30, do_sample=True)[0][\"summary_text\"]\n    summaries.append(summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T19:35:59.454033Z","iopub.execute_input":"2026-01-06T19:35:59.454937Z","iopub.status.idle":"2026-01-06T19:36:06.450900Z","shell.execute_reply.started":"2026-01-06T19:35:59.454874Z","shell.execute_reply":"2026-01-06T19:36:06.450293Z"}},"outputs":[{"name":"stdout","text":"Summarizing chunk 1 of 6\nSummarizing chunk 2 of 6\nSummarizing chunk 3 of 6\nSummarizing chunk 4 of 6\nSummarizing chunk 5 of 6\n","output_type":"stream"},{"name":"stderr","text":"Your max_length is set to 130, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n","output_type":"stream"},{"name":"stdout","text":"Summarizing chunk 6 of 6\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"combined_summary = \" \".join(summaries)\nprint(\"Final Combined Summary:\\n\")\nprint(combined_summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T19:36:13.287644Z","iopub.execute_input":"2026-01-06T19:36:13.288327Z","iopub.status.idle":"2026-01-06T19:36:13.292767Z","shell.execute_reply.started":"2026-01-06T19:36:13.288296Z","shell.execute_reply":"2026-01-06T19:36:13.291985Z"}},"outputs":[{"name":"stdout","text":"Final Combined Summary:\n\nImitation is as important in education as literacy as literacy is in literacy, he says. He says kids have tremendous talents, and we squander them, pretty ruthlessly. \"I heard a great story recently -- I love telling it -- of a little girl who was in a drawing lesson,\" he adds. James Robinson: Kids will take a chance if they don't know, they'll have a go. By the time they get to be adults, most kids have lost that capacity, he says. Robinson: We run our companies like this. We stigmatize mistakes. Every education system on earth has the same hierarchy of subjects. Maths and languages are at the top, the humanities at the bottom. Art and music are normally given a higher status in schools than drama and dance. In the next 30 years, according to UNESCO, more people worldwide will be graduating through education than at any point in history. David Frum: We need to radically rethink our view of intelligence. He says creativity often comes about through interaction of different ways of seeing things. Gillian Lynne went to a dance school because she couldn't sit still. She was eventually auditioned for the Royal Ballet School and became a soloist. Gillian Lynne is responsible for some of the most successful musical productions in history. The aim is to help themmake something of it. The goal is to make a difference to the lives of people around the world. That's our aim. Thank you very much.\n","output_type":"stream"}],"execution_count":6}]}